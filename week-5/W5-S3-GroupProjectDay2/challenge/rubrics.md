# Grading Rubric: Finish the Weather Dashboard

---

### **Technical Functionality – 30%**

Evaluates core application functionality and how well it meets the requirements:

- Converts a **user-entered location** into latitude and longitude using the Geocoding API.
- Successfully retrieves and displays **weather data** for the selected location.
- Displays only the required data: **location name**, **temperature**, and **weather description**.
- UI updates **dynamically** after data is fetched.
- Handles API and user input errors **gracefully** with appropriate feedback.

---

### **JavaScript & API Integration – 20%**

Assesses JavaScript proficiency and effective API usage:

- Correct use of **`fetch()`** or other HTTP methods to call OpenWeatherMap APIs.
- Parses JSON responses and **extracts correct data fields**.
- JavaScript functions are **modular**, **well-named**, and logically structured.
- API key management follows best practices (not hard-coded in public files).

---

### **UI Implementation & DOM Manipulation – 15%**

Focuses on user interface and real-time updates:

- Weather data is inserted dynamically into the DOM.
- Information is **clearly displayed** and formatted appropriately.
- Responsive layout or visually clear **dashboard structure**.
- Good use of semantic HTML elements to organize data presentation.

---

### **Error Handling & Input Validation – 10%**

Measures robustness and user experience during edge cases:

- Invalid inputs (e.g., gibberish locations) are handled with **user-friendly messages**.
- Handles failed API calls or empty responses **without crashing** the app.
- Optional: Loading indicators or status messages while data is being fetched.

---

### **Code Quality & Project Structure – 10%**

Assesses maintainability and code cleanliness:

- Code is well-organized with **clear file separation** (HTML, CSS, JS).
- Uses **meaningful variable and function names**, avoids repetition.
- Includes comments where appropriate and follows **consistent formatting**.
- HTML and JavaScript adhere to best practices.

---

### **Team Participation & Effort – 10%**

Evaluates individual contribution relative to peers:

- Each team member **actively participates** in project planning and execution.
- Tasks are divided **equitably**, and members contribute code, testing, or documentation.
- A lack of visible contribution or noticeable **imbalance in effort** may result in reduced marks for individuals.
- Peer feedback and commit history may inform this evaluation.

---

### **Collaboration & GitHub Workflow – 5%**

Evaluates teamwork and version control practices:

- Use of **branches** and **pull requests** for collaboration.
- Each team member has visible contribution through **commits**.
- Commit messages are **clear and descriptive**.
- Repository contains a well-written `README.md` and clear project setup.

---

## ✅ Total: 100%
